{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV_TO_SQL CONVERTION USING POSTGRES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I am currently working on a data analysis project which involves large csv file,100MB to 6 GB.If we try to load this amount of data in a pandas dataframe, it fails due to memory limitation of a home computer or a laptop.<br>\n",
    "Solution to this is to convert the csv files to sql and then read the sql database in chunks in pandas to conduct our data analysis.<br>\n",
    "This tutorial is useful for anyone who is working on Windows/python and Anaconda framework to conduct the research.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Local Machine configration:\n",
    "Microsoft Windows [Version 10.0.14393]<br>\n",
    "Python 2.7.12 |Anaconda 4.2.0 (64-bit)<br>\n",
    "INSTALLED RAM : 4 GB<br>\n",
    "HARD DISK: 920 GB<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Postgres Database And pscopg2 library to convert csv to postgres.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "nbpresent": {
     "id": "d841d8f7-5bf7-4c46-98de-6e844f8ca879"
    }
   },
   "source": [
    "Postgres SQl can dowloaded from https://www.postgresql.org/download/ by choosing your relavent operating system.After installing postres database,you will need setup your admin password."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful command in postgres sql\n",
    "|command|Description what it does|\n",
    "|---|----------------------------|\n",
    "|\\l  |lists all the database|   \n",
    "|\\c dbname|connect to the database named dbname|\n",
    "|\\dt|list the table in the database you have connected|\n",
    "|select * from tablename;|display all the record from table named tablename|\n",
    "|delete from tablename;|delete all record in the table named tablename.|\n",
    "|show data_directory;|show the curent working directory in postgres|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to check the no of rows for big table,rel name is the name of the table.\n",
    "#SELECT reltuples::bigint AS estimate FROM pg_class where relname='transaction';\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "nbpresent": {
     "id": "22940093-4d8e-45bd-be68-630f2ff2e8a4"
    }
   },
   "source": [
    "Some convention and notes to avoid confusion are as follows.\n",
    "#comments for clarification,not to be used on the sql prompt.\n",
    "Screen shot only for first few examples and important example only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database 'test' was created sucessfully.\n"
     ]
    }
   ],
   "source": [
    "# create a database named testing in postgres\n",
    "#create database test;\n",
    "import psycopg2\n",
    "conn = psycopg2.connect(host=\"localhost\",dbname=\"postgres\",user=\"postgres\",password=\"ram501shi\")\n",
    "\n",
    "# this statement will at commit all statements\n",
    "conn.autocommit=True\n",
    "cur=conn.cursor()\n",
    "dname='test'\n",
    "cur.execute('CREATE DATABASE '+dname)\n",
    "print(\"Database '\"+dname+\"' was created sucessfully.\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "nbpresent": {
     "id": "e8a92e61-4537-471d-a494-2dc4a9c5b729"
    }
   },
   "source": [
    "We want to convert csv files into sql tables which reside in a database named \"test\".Their is a possiblity that we want to convert one csv file to one corresponding sql table or convert multiple csv file and merge them into a single sql table.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "nbpresent": {
     "id": "68f3dfdd-6c4f-49ea-88f6-740019845cd4"
    }
   },
   "source": [
    "Below is the sample of csv we will convert to database table.We use the %load \"filename\" command to display the contents of the csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load ./data/db1/data.csv\n",
    "store_id\tstate_code\tpost_code\tgroup_store\\n\n",
    "1\tVIC\t3558\t0\n",
    "2\tVIC\t3124\t0\n",
    "3\tWA\t6107\t1\n",
    "4\tVIC\t3214\t0\n",
    "5\tVIC\t3172\t0\n",
    "6\tNSW\t2089\t0\n",
    "7\tNSW\t2460\t0\n",
    "8\tVIC\t3107\t0\n",
    "9\tVIC\t3130\t0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We create a table structure similar to the csv file before converting in the csv file to a postgres database table."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "nbpresent": {
     "id": "1e8e85d4-2763-4fac-ad62-93a12faa33b2"
    }
   },
   "source": [
    "Command  |\n",
    "---------|\n",
    "\n",
    "create table store(store_id integer primary key not null,\"state_code\" text null,post_code integer not null,group_store bool not null);\n",
    "Explanation\n",
    "# create table is the command followed by the name of the table you want to create ie \"store\" in this case  \n",
    "# store_id is the name of the column followed by the data type you want it to be,primary key  \n",
    "# to specify that this is the primary key and it is not null.\n",
    "# Followed by a ','comma.Similarly we define all the coulumns in the table.\n",
    "# use exactly the same name and quote \"\" while using copy for the column names. else copy from will not work.\n",
    "# command below.\n",
    "create table store(store_id integer primary key not null,\"state_code\" text null,post_code integer not null,group_store bool not null);\n",
    "# The command above created the table structure below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table store created\n"
     ]
    }
   ],
   "source": [
    "conn = psycopg2.connect(host=\"localhost\",database=\"test\",user=\"postgres\",password=\"ram501shi\")\n",
    "# this statement will at commit all statements\n",
    "conn.autocommit=True\n",
    "cur=conn.cursor()\n",
    "cur.execute('create table store(store_id integer primary key not null,\"state_code\" text null,post_code integer not null,group_store bool not null);')\n",
    "print(\"Table store created\")\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "conn = psycopg2.connect(host=\"localhost\",database=\"test\",user=\"postgres\",password=\"ram501shi\")\n",
    "# this statement will at commit all statements\n",
    "conn.autocommit=True\n",
    "cur=conn.cursor()\n",
    "cur.execute(\"select * from store;\")\n",
    "data=cur.fetchall()\n",
    "print data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "93ef31d8-89fa-48ec-bd74-6d400910d254"
    }
   },
   "source": [
    "Display the table structure we created.If you use psycopg2 to display the strucure using the select statement it display an empty list as above,Hence we display the result in psql prompt below for more clarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./figures/sc2.png\">\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "nbpresent": {
     "id": "3304984e-42ea-4f74-9a96-e74b56218792"
    }
   },
   "source": [
    "Next step is to insert all the records from data.csv to the store table structure we created above using the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the location of the file : ../../../../../Users/SwapnaDev/Desktop/DataScience-Project/CSV_TO_SQL_CONVERTION/data/db1/data.csv\n",
      "copy store(store_id,state_code,post_code,group_store) from '../../../../../Users/SwapnaDev/Desktop/DataScience-Project/CSV_TO_SQL_CONVERTION/data/db1/data.csv' DELIMITER E'\\t' csv header;\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import glob \n",
    "conn = psycopg2.connect(host=\"localhost\",database=\"test\",user=\"postgres\",password=\"ram501shi\")\n",
    "# this statement will at commit all statements\n",
    "conn.autocommit=True\n",
    "# we use r prefix to indicate we want the data raw.Abosolute path or relative path can be used just have to get the path right.\n",
    "# we use relative path ie from   C:/Program Files/PostgreSQL/9.6/data where the database is located to where the csv file is \n",
    "# located on the local machine. ../../../../will bring us to C:// then we navigate to the data location \n",
    "# ie /Users/SwapnaDev/Desktop/DataScience-Project/CSV_TO_SQL_CONVERTION/data/test.csv'\n",
    "file=glob.glob(r'../../../../../Users/SwapnaDev/Desktop/DataScience-Project/CSV_TO_SQL_CONVERTION/data/db1/data.csv')\n",
    "print\"This is the location of the file :\",file[0]\n",
    "# constructing the sql statement to pass\n",
    "# \"copy store(store_id,state_code,post_code,group_store) from \" copy command followed by the database name \"store\" and its filed\n",
    "# in the brackers from \n",
    "# \" +\"'\"+file+\"'\"+ : double quotes used as escape squence for single quote which is reqiured for the file path\n",
    "#DELIMITER E'\\\\t' csv header;\" :: delimiter of the file ie tab E\\\\t E is required and \\ escape seq for \\t followed by csv header. \n",
    "sql=\"copy store(store_id,state_code,post_code,group_store) from \" +\"'\"+file[0]+\"'\"+\" DELIMITER E'\\\\t' csv header;\"\n",
    "print sql\n",
    "cur=conn.cursor()\n",
    "cur.execute(sql)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if the data was added from the test.csv file to the database.\n",
      "(1, 'VIC', 3558, False)\n",
      "(2, 'VIC', 3124, False)\n",
      "(3, 'WA', 6107, True)\n",
      "(4, 'VIC', 3214, False)\n",
      "(5, 'VIC', 3172, False)\n",
      "(6, 'NSW', 2089, False)\n",
      "(7, 'NSW', 2460, False)\n",
      "(8, 'VIC', 3107, False)\n",
      "(9, 'VIC', 3130, False)\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "conn = psycopg2.connect(host=\"localhost\",database=\"test\",user=\"postgres\",password=\"ram501shi\")\n",
    "cu=conn.cursor()\n",
    "cu.execute(\"select * from store;\")\n",
    "a=cu.fetchall()\n",
    "print \"Checking if the data was added from the test.csv file to the database.\"\n",
    "for item in a:\n",
    "    print item\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "4072fdaa-2ad3-4988-99f6-707c91d9e624"
    }
   },
   "source": [
    "Also screenshot from the psql prompt.\n",
    "<img src='./figures/sc3.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we want convert multiple file in csv format in to SQL table."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "8d454e93-2dcf-491b-adda-d7e971ae63ac"
    }
   },
   "source": [
    "1) we could possibly do it postgres sql ie. write a for loop and pass all the file names(*.csv) and use the command COPY FROM IN \n",
    "   PSOTGRES SQL to achieve the result. Check postgrsql documentation on how to do this.\n",
    "2) We will achieve the result using a module called psycopg2 and python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "8ec215e8-3a46-42a1-ad5b-fe59a6afacbd"
    }
   },
   "outputs": [],
   "source": [
    "# import glob to use it to get all the file name in a directory.\n",
    "# there are 2 file in this directory we want to convert to sql database.\n",
    "#import glob module\n",
    "import glob\n",
    "# A list, named \"file\" having the paths of file we want to convert csv to sql. \n",
    "file=glob.glob(r'../../../../../Users/SwapnaDev/Desktop/DataScience-Project/CSV_TO_SQL_CONVERTION/data/db2/*.*')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "e5a8d8cb-c731-4e0f-8594-a0f7f8564da9"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../../../../../Users/SwapnaDev/Desktop/DataScience-Project/CSV_TO_SQL_CONVERTION/data/db2\\\\test.csv', '../../../../../Users/SwapnaDev/Desktop/DataScience-Project/CSV_TO_SQL_CONVERTION/data/db2\\\\test1.csv']\n"
     ]
    }
   ],
   "source": [
    "# print the list,named \"file\"\n",
    "print file\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "d5b31fc2-be2a-47c0-9911-5653abacbd62"
    }
   },
   "outputs": [],
   "source": [
    "# we notice that 2 backslash \"\\\\\" in the file path which we need to convert front slash \"/\" \n",
    "# define a empty list new, for storage\n",
    "new=[]\n",
    "# looping through list name, \"file\" until the last element of the list.\n",
    "for all in range(len(file)):\n",
    "    # replacing first item in the \"list\"  with the correct slash for windows file path and storing in a variable called var \n",
    "    var=file[all].replace('\\\\','/')\n",
    "    #appending the var to a list called new.\n",
    "    new.append(var)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../../../../../Users/SwapnaDev/Desktop/DataScience-Project/CSV_TO_SQL_CONVERTION/data/db2/test.csv', '../../../../../Users/SwapnaDev/Desktop/DataScience-Project/CSV_TO_SQL_CONVERTION/data/db2/test1.csv']\n"
     ]
    }
   ],
   "source": [
    "# list with the correct path for windows\n",
    "print new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "3d40f3c0-3c79-4dd9-86fd-aef2d22e651e"
    }
   },
   "outputs": [],
   "source": [
    "# declaration a conn variable to connect to the postgres sql database\n",
    "conn = psycopg2.connect(host=\"localhost\",database=\"test\",user=\"postgres\",password=\"ram501shi\")\n",
    "cur=conn.cursor()\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Before we convert the csv file to sql table we have to create a table named \"store1\" in postgres sql with similar structure as test.csv and test1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load ./data/db2/test.csv\n",
    "store_id\tstate_code\tpost_code\tgroup_store\n",
    "1\tVIC\t3558\t0\n",
    "2\tVIC\t3124\t0\n",
    "3\tWA\t6107\t1\n",
    "4\tVIC\t3214\t0\n",
    "5\tVIC\t3172\t0\n",
    "6\tNSW\t2089\t0\n",
    "7\tNSW\t2460\t0\n",
    "8\tVIC\t3107\t0\n",
    "9\tVIC\t3130\t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load ./data/db2/test1.csv\n",
    "store_id\tstate_code\tpost_code\tgroup_store\n",
    "10\tVIC\t3434\t0\n",
    "11\tVIC\t3134\t0\n",
    "12\tWA\t6007\t1\n",
    "13\tVIC\t3614\t0\n",
    "14\tVIC\t3972\t0\n",
    "15\tNSW\t2039\t0\n",
    "16\tNSW\t2460\t0\n",
    "17\tVIC\t3177\t0\n",
    "18\tVIC\t3180\t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "14087e54-75d3-45b0-8862-818a521a8e54"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table structure for store1 created\n"
     ]
    }
   ],
   "source": [
    "#using cur.execute\n",
    "#Create a database name store1 with columns name as store id,state_code,post_code,group_store and defining the variable type\n",
    "conn=psycopg2.connect(host=\"localhost\",database=\"test\",user=\"postgres\",password=\"ram501shi\")\n",
    "conn.autocommit=True\n",
    "cur=conn.cursor()\n",
    "cur.execute(\"create table store1(store_id integer primary key,state_code text,post_code integer,group_store bool);\")\n",
    "print(\"Table structure for \"+\"store1\"+\" created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us confirm that that the table \"store1\" exsists in psql."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The strucure for store1 is created but it has no data in it.Hence an empty list is displayed below.\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"select * from store1;\")\n",
    "data=cur.fetchall()\n",
    "print(\"The strucure for store1 is created but it has no data in it.Hence an empty list is displayed below.\")\n",
    "print data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We want use copy_expert method of \"cursor\" to convert the 2 csv file in a directory into the sql tables.\n",
    "We have created the empty table named \"store\" with the same structure as the csv fle."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#We want to pass 2 parameters to the copy_expert method.\n",
    "sql-- sql statement,we will pass the copy statement used previously in prostgres sql. \n",
    "f --- as reference to open the file.\n",
    "Since we are converting multiple csv to sql table,we declare variable called sql and construct the sql statement in this format.\n",
    "\n",
    "copy store(store_id,state_code,post_code,group_store) from 'C:/file path' delimiter E'\\t' csv header\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "d767309f-78ed-44c9-94bc-4c0c044b3b0a"
    }
   },
   "outputs": [],
   "source": [
    "# we iterate through the list called \"new\" while length of list is less than length of the list new\n",
    "for text in range(len(new)):\n",
    "    connection=psycopg2.connect(host=\"localhost\",database=\"test\",user=\"postgres\",password=\"ram501shi\")\n",
    "    #make auto commit to the db.\n",
    "    connection.autocommit=True\n",
    "    cur=connection.cursor()\n",
    "    # open the file and pass the first file   \n",
    "    f=open(new[text],'r')\n",
    "    # construct the sql statement\n",
    "    sql=\"copy store1(store_id,state_code,post_code,group_store) from \"+\"'\"+new[text]+\"'\" +\" delimiter E'\\\\t' csv header;\"\n",
    "    #print \"connection file is :\",f\n",
    "    #print \"printing sql for each file:\"\n",
    "    #print sql\n",
    "    #pass the sql and f to the copy_expert method\n",
    "    cur.copy_expert(sql,f)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./figures/sc5.png'>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Note if we run the above code again it will not run as we have defined store_id as primary key which should be unique.Hence the error.Example is below."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------\n",
    "IntegrityError                            Traceback (most recent call last)\n",
    "<ipython-input-23-80ebbd27fec3> in <module>()\n",
    "      6     sql=\"copy store(store_id,state_code,post_code,group_store) from \"+ \"\\'\"+new[text] + \"\\'\"+ \"delimiter E'\\\\t' csv header\"\n",
    "      7     # pass the sql and f to the copy_expert method\n",
    "----> 8     cur.copy_expert(sql,f)\n",
    "      9     # commit the results.\n",
    "     10     conn.commit()\n",
    "\n",
    "IntegrityError: duplicate key value violates unique constraint \"store_pkey\"\n",
    "DETAIL:  Key (store_id)=(1) already exists.\n",
    "CONTEXT:  COPY store, line 2"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "nbpresent": {
   "slides": {},
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
